{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import keras.layers as layers\n",
    "import keras.optimizers as optimizers\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, ReduceLROnPlateau\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "\n",
    "import threading, random, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator\n",
    "\n",
    "원본 이미지와 라벨 데이터를 가져오고, 이 이미지와 라벨을 패널로 나누어 학습 데이터와 라벨을 생성하는 커스텀 생성기를 작성하는 부분."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "원본 이미지와 라벨 데이터를 가져온다. 코드를 실행하기 전에 코드와 같은 폴더에 데이터셋을 다운받는다.   \n",
    "\n",
    "https://www.kaggle.com/kairess/find-waldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m imgs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mdataset/imgs_uint8.npy\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32) \u001b[39m/\u001b[39m \u001b[39m255.\u001b[39m\n\u001b[0;32m      2\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mdataset/labels_uint8.npy\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32) \u001b[39m/\u001b[39m \u001b[39m255.\u001b[39m\n\u001b[1;32m----> 3\u001b[0m waldo_sub_imgs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mdataset/waldo_sub_imgs_uint8.npy\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m/\u001b[39m \u001b[39m255.\u001b[39m\n\u001b[0;32m      4\u001b[0m waldo_sub_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mdataset/waldo_sub_labels_uint8.npy\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m255.\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\tak_jj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:413\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode)\n\u001b[0;32m    412\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 413\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[0;32m    414\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs)\n\u001b[0;32m    415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Users\\tak_jj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\format.py:741\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mhasobject:\n\u001b[0;32m    739\u001b[0m     \u001b[39m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n\u001b[1;32m--> 741\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mObject arrays cannot be loaded when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    742\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mallow_pickle=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    743\u001b[0m     \u001b[39mif\u001b[39;00m pickle_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    744\u001b[0m         pickle_kwargs \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "imgs = np.load('dataset/imgs_uint8.npy').astype(np.float32) / 255.\n",
    "labels = np.load('dataset/labels_uint8.npy').astype(np.float32) / 255.\n",
    "waldo_sub_imgs = np.load('dataset/waldo_sub_imgs_uint8.npy') / 255.\n",
    "waldo_sub_labels = np.load('dataset/waldo_sub_labels_uint8.npy') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 코드 작성시와 numpy 버전 차이가 있어 waldo_sub_imgs와 waldo_sub_labels를 로드할 때 오류가 발생한다. allow_pickle 파라메터의 기본값이 True에서 False로 바뀌어 발생하는 문제로 ```allow_pickle=True```를 코드에 추가해주면 해결된다.\n",
    "\n",
    "pickle은 파이썬에서 제공하는 모듈로 자료형의 변화 없이 데이터를 저장하고 불러올 수 있게해준다. 다만 악의적으로 제작된 데이터를 불러올 경우 임의로 코드를 실행하는 문제가 있을 수 있기 때문에 보안상의 문제로 기본값이 변경된 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.load('dataset/imgs_uint8.npy').astype(np.float32) / 255.\n",
    "labels = np.load('dataset/labels_uint8.npy').astype(np.float32) / 255.\n",
    "waldo_sub_imgs = np.load('dataset/waldo_sub_imgs_uint8.npy', allow_pickle=True) / 255.\n",
    "waldo_sub_labels = np.load('dataset/waldo_sub_labels_uint8.npy', allow_pickle=True) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 1760, 2800, 3) (18, 1760, 2800)\n"
     ]
    }
   ],
   "source": [
    "print(imgs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 imgs와 labels의 형태를 확인한다.   \n",
    "imgs는 1760*2800 크기의 이미지 18장으로 RGB 데이터값이 입력된 numpy배열이다.\n",
    "labels는 똑같은 이미지에서 waldo가 있는 부분을 255, 아닌 부분을 0으로 표시한 numpy배열이다.\n",
    "\n",
    "데이터를 학습에 적합한 형태로 (0과 1사이의 값으로) 바꾸기 위해 255로 나눠준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,) (18,)\n",
      "(379, 397, 3) (386, 394, 3)\n"
     ]
    }
   ],
   "source": [
    "print(waldo_sub_imgs.shape, waldo_sub_labels.shape)\n",
    "print(waldo_sub_imgs[0].shape, waldo_sub_imgs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 waldo_sub_imgs와 waldo_sub_labels의 형태를 확인한다.\n",
    "waldo_sub_imgs는 imgs에서 waldo가 있는 부분과 그 주변을 잘라낸 이미지로 imgs와 마찬가지로 RGB 데이터값을 가진 이미지 18장의 numpy배열이다.   \n",
    "자른 크기는 각각 다름을 확인할 수 있다.\n",
    "waldo_sub_labels는 labels와 동일하게 waldo_sub_imgs와 동일한 크기인 waldo가 있는 부분을 255, 아닌 부분을 0으로 표시한 numpy 배열이다.\n",
    "\n",
    "역시 데이터를 학습에 적합한 형태로 바꾸기 위해 255로 나눠준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "이 코드에서는 이미지를 패널로 나누어 모델 학습을 진행한다.   \n",
    "학습을 위해 이미지와 라벨을 패널로 분할해 데이터를 만드는 생성기를 작성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchIndices(object):\n",
    "    def __init__(self, n, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = n,bs,shuffle\n",
    "        self.lock = threading.Lock()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.idxs = (np.random.permutation(self.n) \n",
    "                     if self.shuffle else np.arange(0, self.n))\n",
    "        self.curr = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            if self.curr >= self.n: self.reset()\n",
    "            ni = min(self.bs, self.n-self.curr)\n",
    "            res = self.idxs[self.curr:self.curr+ni]\n",
    "            self.curr += ni\n",
    "            return res\n",
    "        \n",
    "class segm_generator(object):\n",
    "    def __init__(self, x, y, bs=64, out_sz=(224,224), train=True, waldo=True):\n",
    "        self.x, self.y, self.bs, self.train = x,y,bs,train\n",
    "        self.waldo = waldo\n",
    "        self.n = x.shape[0]\n",
    "        self.ri, self.ci = [], []\n",
    "        for i in range(self.n):\n",
    "            ri, ci, _ = x[i].shape\n",
    "            self.ri.append(ri), self.ci.append(ci) \n",
    "        self.idx_gen = BatchIndices(self.n, bs, train)\n",
    "        self.ro, self.co = out_sz\n",
    "        \n",
    "    def get_slice(self, i,o):\n",
    "        start = random.randint(0, i-o) if self.train else (i-o)\n",
    "        return slice(start, start+o)\n",
    "\n",
    "    def get_item(self, idx):\n",
    "        slice_r = self.get_slice(self.ri[idx], self.ro)\n",
    "        slice_c = self.get_slice(self.ci[idx], self.co)\n",
    "        x = self.x[idx][slice_r, slice_c]\n",
    "        y = self.y[idx][slice_r, slice_c]\n",
    "        if self.train and (random.random()>0.5): \n",
    "            y = y[:,::-1]\n",
    "            x = x[:,::-1]\n",
    "        if not self.waldo and np.sum(y)!=0:\n",
    "            return None\n",
    "\n",
    "        return x, to_categorical(y, num_classes=2).reshape((y.shape[0] * y.shape[1], 2))\n",
    "\n",
    "    def __next__(self):\n",
    "        idxs = self.idx_gen.__next__()\n",
    "        items = []\n",
    "        for idx in idxs:\n",
    "            item = self.get_item(idx)\n",
    "            if item is not None:\n",
    "                items.append(item)\n",
    "        if not items:\n",
    "            return None\n",
    "        xs,ys = zip(*tuple(items))\n",
    "        return np.stack(xs), np.stack(ys)\n",
    "        \n",
    "def seg_gen_mix(x1, y1, x2, y2, tot_bs=4, prop=0.34, out_sz=(224,224), train=True):\n",
    "    n1 = int(tot_bs*prop)\n",
    "    n2 = tot_bs - n1\n",
    "    sg1 = segm_generator(x1, y1, n1, out_sz = out_sz ,train=train)\n",
    "    sg2 = segm_generator(x2, y2, n2, out_sz = out_sz ,train=train, waldo=False)\n",
    "    while True:\n",
    "        out1 = sg1.__next__()\n",
    "        out2 = sg2.__next__()\n",
    "        if out2 is None:\n",
    "            yield out1\n",
    "        else:\n",
    "            yield np.concatenate((out1[0], out2[0])), np.concatenate((out1[1], out2[1]))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seg_gen_mix라는 함수를 만들기 위해 BatchIndice와 segm_generator라는 클래스를 설정한다. 각각의 변수가 어떤 의미를 가지는지 이해하는 것이 중요하다.\n",
    "\n",
    "변수 확인을 위해 seg_gen_mix 함수의 파라메터를 먼저 확인한다.   \n",
    "x1, y1은 위에서 가져온 waldo_sub_imgs와 waldo_sub_labels, x2, y2는 imgs와 labels가 들어간다.   \n",
    "tot_bs와 prop는 한번의 batch에서 생성할 패널의 최대 개수와 그 중 x1과 y1을 이용해 생성할 패널의 비율을 설정하는 파라메터이다.   \n",
    "out_sz는 생성할 패널의 크기를 지정한다.   \n",
    "train은 추가적인 옵션을 바꾸기 위해 설정한 boolean값이다.\n",
    "\n",
    "이제 함수에서 사용되는 segm_generator instance 생성 부분 파라메터값을 보면 이미지와 라벨, tot_bs와 prop를 활용하여 만든 생성할 이미지의 개수, 패널의 크기, train 옵션, waldo 옵션이 들어가는걸 볼 수 있다. imgs와 labels를 이용한 instance 생성에는 waldo가 False로 설정되어있다.\n",
    "\n",
    "segm_generator class를 설정하는 부분에서 BatchIndice instance를 생성하는 부분을 보면 self.n, bs, train 값을 전달하는걸 확인할 수 있다. bs와 train은 앞서 전달받은 생성할 이미지의 개수와 train 옵션의 값이고 self.n의 경우 들어온 이미지의 0번 인덱스 즉 입력된 데이터의 이미지 개수(이 경우에는 18장)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class BatchIndices(object):\n",
    "    def __init__(self, n, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = n,bs,shuffle\n",
    "        self.lock = threading.Lock()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.idxs = (np.random.permutation(self.n) \n",
    "                     if self.shuffle else np.arange(0, self.n))\n",
    "        self.curr = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            if self.curr >= self.n: self.reset()\n",
    "            ni = min(self.bs, self.n-self.curr)\n",
    "            res = self.idxs[self.curr:self.curr+ni]\n",
    "            self.curr += ni\n",
    "            return res\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "303a7a08249a5473dea6ff8636be56c985548da680474adfe7e313b1484f1de6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
